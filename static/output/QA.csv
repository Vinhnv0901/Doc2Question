Question,Answer
What is the difference between Attention Map Flow and Temporal Processing Adapters?,"Parallel adapters only need to learn the change in distribution to be added to the pre- trained model. On the other hand, serial adapters accom- modate this change along with the information that passes through the model. Therefore, for our requirements, , scaled parallel adapters are added to the model, and AM flow is concatenated with adapters across the self-attention mod- ules. Various temporal processing modules (TPMs) along with the image model branch give output logits which are averaged, giving the final output. Details are given below."
"What is a benefit of our method has to do with the downsampled embedding from this adapter, providing rich spatial information, pertaining to motion?","With irrelevant motion in the frames, AM flow is noisy, as the patches with change are not only due to the action but also to motion. The aligning encoder resolves this issue (as demon- strated in the appendix)."
What are the three datasets used for this work?,Something-Something v2 Kinetics-400 Toyota Smarthome
What is the name of the adapter used in this paper?,"Parallel AdaptersEmbedding for temporal reasoning The basic block of adapters works well for this purpose, as they inherently pro- vide a downsampled embedding. Parallel adapters only need to learn the change in distribution to be added to the pre- trained model. On the other hand, serial adapters accom- modate this change along with the information that passes through the model. Therefore, for our requirements, JFT-3B+ALIGN-1.8B N/A 1000+ 1000+ N/A 88.9 - MTV-H (Yan et al. 2022) ViT-H+B+S+TIN-21K+WTS-600M3234 1000+ 1000+ 44.5 89.1 98.2 Full tuning UniFormerV2-B (Li et al. 2023a) ViT-B CLIP-400M 834 115 115 1.6 84.4 96.3 UniFormerV2-L (Li et al. 2023a) ViT-L CLIP-400M 834 354 354 8.0 87.7 97.9 UniFormerV2-L (Li et al. 2023a) ViT-B CLIP-400M 3231 93 7 1.8 82.7 96.2 Parameter Efficient Tuning ST-Adapter (Pan et al. 2022) ViT-B CLIP-400M 3231 93 7 1.8 82.7 96.2 Parameter Efficient Tuning ST-Adapter (Pan et al. 2022) ViT-B CLIP-400M 3231 93 7 1.8 82.7 96.2 Parameter Efficient Tuning ST-Adapter (Pan et al. 2022) ViT-B CLIP-400M 3231 93 7 1.8 82.7 96.2 Parameter Efficient Tuning ST-Adapter (Pan et al. 2022) ViT-B CLIP-400M 3231"
How is AM flow concatenated with adapters across the self-attention mod- ules?,"Scaled parallel adapters are added to the model, and AM flow is concatenated with adapters across the self-attention mod- ules. Various temporal processing modules (TPMs) along with the image model branch give output logits which are averaged, giving the final output. Details are given below. Foundation Models and Adding Adapters Today, most of the foundation models in computer vision are transformer-based. This work exclusively focused on these. As stated above, we choose ViT trained using Dinov2 for this work. Adapters are added to individual transformer encoders/blocks, making this method applicable to all model architectures. For completeness, we use CLIP as the two frames used to compute AM flow."
What is the name of the block of adapters that are used for temporal reasoning?,"Parallel AdaptersEmbedding for temporal reasoning The basic block of adapters works well for this purpose, as they inherently pro- vide a downsampled embedding. Parallel adapters only need to learn the change in distribution to be added to the pre- trained model. On the other hand, serial adapters accom- modate this change along with the information that passes through the model. Therefore, for our requirements, scaled parallel adapters are added to the model, and AM flow is concatenated with adapters across the self-attention mod- ules."
"What is the difference of normalised, aggregated significance of pixels for two frames?",XAt = QtKT tdK
What are the two frames used to compute AM flow?,XAt = AligningEncoder (softmax( QtKT tdK )T 1)
What is the name of the dataset used to evaluate the model?,Something-Something v2
What is the name of the algorithm used in the training of SSv2?,"AM/12, Transformer ViT-B(Dinov2) IN-21K 831 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours - AM/12, Transformer ViT-B(Dinov2) IN-21K 3231 86+32+45+10332+45+103 6.9 89.1 98.3 Ours "
What is the purpose of the experiment on the Smarthome dataset?,Location of AM Flow addition
What is the name of the MViTv2-L?,Vanilla ViT with self-supervised pretraining for 1600 epochs
What are the parameters broken into components?,"backbone, AM flow and linear layers, aligning encoder, and temporal processing module"
What is the main idea of the paper?,Improved action recognition with separable spatio-temporal attention using alternative skeletal and video pre-processing
What is the name of the device that is used to tune the UniFormer V2-B?,ST-Adapter
What does AM/12 mean?,AM flow is added to all 12 transformer blocks
What is the main idea of the paper?,Improved action recognition with separable spatio-temporal attention using alternative skeletal and video pre-processing
What is the name of the model-based multimodal network for hu- man action recognition in rgb-d videos?,Mmnet
"What is the name of the paper Das, S., Sharma, S., Dai, R., Bremond, F., and Thonnat, M. 2020. VPN: Learning video-pose embeddings for activities of daily living. In Proc. Eur. Conf. Comput. Vis. , 72â€“90. Springer?",VPN: Learning video-pose embeddings for activities of daily living
"What is the name of the paper that Feichtenhofer, Fan, H., Malik, J., and He, K. 2019 Slowfast networks for video recognition?",Proceedings of the IEEE/CVF international conference on computer vision
What is the name of the paper that focuses on visual prompt tuning?,Convolutional bypasses are better vision transformer adapters
What is the main idea of UniFormerV2?,Unlocking the Potential of Image ViTs for Video Understanding
What is the first name of the person who developed Mvitv2: Improved Multiscale Vision Transformers for Classification and Detection?,Feichtenhofer
"What is the first name of the person who wrote ""Video Swin Transformer""?",Liu
"What is the name of the paper in which Pan, J., Chen, S., Shou, M. Z., Liu, Y., Shao, J., and Li, H. 2021. Actor-context-actor relation network for spatio-temporal action localization?",St- adapter: Parameter-efficient image-to-video transfer learn- ing
What is the first name of the person who wrote Hiera: A Hierarchical Vision Transformer without the Bells-and- Whistles?,Feichtenhofer
What is a unified framework for real-world skeleton-based action recognition?,Unik
What is the first word in the first paragraph of the text?,Helpful
